# This is a sample Python script.

# Press Shift+F10 to execute it or replace it with your code.
# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.
import math
import sys
import random
import matplotlib.pyplot as plt

import numpy as np

import numpy as np


def test_after_train(W, B):
    pass


def insert_w_b(W, B, in_x, dim_out):
    sd_w, sd_b = math.sqrt(6 / (in_x + dim_out)), math.sqrt(6 / (1 + dim_out)),
    w1 = np.random.uniform(-sd_w, sd_w, (in_x, dim_out))
    b1 = np.random.uniform(-sd_b, sd_b, (1, dim_out))
    W.append(np.array(w1))
    B.append(np.array(b1))


def softmax(x):
    """ applies softmax to an input x"""
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum()


sigmoid = lambda x: 1 / (1 + np.exp(-x))


def create_dims(layer_num):
    return [128 * layer_num]
    pass


def update_parameters(loss, parameters, W, B):
    pass


def create_w_b(train_x, layer_num):
    in_x = len(train_x[0])
    # dim of layer
    dim = 128
    sd = 0
    W, B = [], []
    insert_w_b(W, B, in_x, dim)
    in_x = dim
    for i in range(1, layer_num - 1):
        insert_w_b(W, B, in_x, dim)
    insert_w_b(W, B, in_x, 10)


def calculate_loss(W, train_x, train_y):
    pass


def forward_instance(x, W, B, layers_num):
    H, Z = [], []
    for i in range (0, layers_num):
        zi = np.dot(W[i], x) + B[i]
        if i != layers_num - 1:
            hi = sigmoid(zi)
        else:
            hi = softmax(zi)
        H.append(zi)
        Z.append(hi)
    return H,Z




def output_prediction(predictions):
    f1 = open('test_y', 'w')
    for i in range(0, len(predictions)):
        f1.write(str(predictions[i]) + "\n")
    f1.close()


def neural_network(train_x, train_y, ephocs, layers_num):
    W, B = create_w_b(train_x, layers_num)
    for e in range(ephocs):
        Xconvert = []
        temp = list(zip(train_x, train_y))
        random.shuffle(temp)
        pxlist1, pylist1 = zip(*temp)
        for x, y in zip(pxlist1, pylist1):
            parameters = forward_instance(x)
            loss = calculate_loss(W, train_x, train_y)
            W = update_parameters(loss, parameters, W, B)


def mini_set():
    # parameters should be: train_x train_y
    training_examples, training_labels = sys.argv[1], sys.argv[2]
    taken = random.sample(range(1, 55001), 5000)
    taken.sort()
    print(taken)
    with open('train_x_short', 'w') as out1:
        i = 1
        f1 = open(training_examples)
        for line1 in f1:
            if i in taken:
                out1.write(line1)
            i += 1
        f1.close()
    with open('train_y_short', 'w') as out2:
        i = 1
        f2 = open(training_labels)
        for line2 in f2:
            if i in taken:
                out2.write(line2)
            i += 1
        f2.close()


def load_data(path_x, path_y):
    train_x = np.loadtxt(path_x)
    train_y = np.loadtxt(path_y)
    print(type(train_x[0]))
    '''
    for i in range (0,5000):
        plt.imshow(train_x[i].reshape(28, -1), cmap="gray")
        plt.show()
    '''
    return train_x, train_y


# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    layer_num = 3
    mini_set()
    train_x, train_y = load_data("train_x_short", "train_y_short")
# W, B = neural_network(train_x, train_y)
# prediction = test_after_train(W, B)
# output_prediction([1, 2, 3, 4])
